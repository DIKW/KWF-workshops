{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import zipfile\n",
    "from nltk.corpus.reader import PlaintextCorpusReader\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "import re\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer() \n",
    "from collections import Counter\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip_file = \"/home/ana/mytemp/DIKW/CDSP_Python/programma/datasets/data_for_windows.zip\"\n",
    "directory_to_extract_to = \"/home/ana/temp/tmp1\"\n",
    "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "    zip_ref.extractall(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_root = directory_to_extract_to + \"/data/lyrics/\"\n",
    "file_ext = \"txt\"\n",
    "fileids = [f for f in listdir(corpus_root) if isfile(join(corpus_root, f)) and f.lower().endswith(file_ext)]\n",
    "corpus = PlaintextCorpusReader(corpus_root, fileids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets put all the data in a dataframe, using song_id as index\n",
    "df_corps = pd.DataFrame(columns=['song_id', 'Text'])\n",
    "df_corps['song_id'] = [i for i in fileids]\n",
    "df_corps['Text'] = [corpus.raw(i) for i in fileids]\n",
    "df_corps.set_index('song_id', inplace=True)\n",
    "df_corps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove songs having 10 lines or less\n",
    "df_corps['line_count'] = np.nan\n",
    "df_corps.loc[:, 'line_count'] =[df_corps.loc[i, \"Text\"].count('\\n') for i in df_corps.index]\n",
    "df_corps.sort_values(\"line_count\")\n",
    "df_corps = df_corps[df_corps.line_count > 10]\n",
    "df_corps.sort_values(\"line_count\")\n",
    "df_corps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup the text\n",
    "def preprocess(sentence):\n",
    "    sentence=str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence=sentence.replace('{html}',\"\") \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(rem_num)  \n",
    "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
    "    # stem_words=[stemmer.stem(w) for w in filtered_words]\n",
    "    # lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "\n",
    "df_corps['cleanText'] = df_corps['Text'].map(lambda s:preprocess(s)) \n",
    "df_corps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the term frequencies for a couple of songs\n",
    "\n",
    "df_term_freq = pd.DataFrame(columns=['song_id', 'word', 'n', 'total'])\n",
    "\n",
    "song_list = [\"Pearl_Jam_Black.txt\", \"James_Brown_Sex_Machine.txt\",\n",
    "               \"The_Blues_Brothers_Everybody_Needs_Somebody_To_Love.txt\",\"Justin_Timberlake_Cry_Me_A_River.txt\"]\n",
    "\n",
    "for song_id in song_list:\n",
    "    list_with_words = ' '.join([df_corps.loc[song_id, 'cleanText']]).lower().split()\n",
    "    freq = nltk.FreqDist(list_with_words)\n",
    "    max = len(freq.most_common())\n",
    "    if max > 100: max = 100\n",
    "    total = len(list_with_words)\n",
    "    for i in range(0,max):\n",
    "        word = freq.most_common()[i][0]\n",
    "        n = freq.most_common()[i][1]\n",
    "        # safe way to append rows to dataframe\n",
    "        df2 = pd.DataFrame([[song_id, word, n ,total]], columns=['song_id', 'word', 'n', 'total'])\n",
    "        df_term_freq = pd.concat([df_term_freq, df2])\n",
    "\n",
    "df_term_freq[\"term_frequency\"] = df_term_freq.apply(lambda row: row[\"n\"] / row.total, axis=1)\n",
    "\n",
    "df_term_freq.sort_values(\"n\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zipf’s law\n",
    "\n",
    "Zipf’s law states that the frequency that a word appears is inversely proportional to its rank. Lets have a look at a single song and see if the frequency times the rank is sort of constant. As the rank increments by one, two words having the same frequency have a different frequency*rank value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = {}\n",
    "\n",
    "# for song in song_list:\n",
    "#     cnt = Counter()\n",
    "#     total_words = len(corpus.raw(song).lower().split())\n",
    "\n",
    "song=\"Michael_Jackson_Wanna_Be_Startin__Something.txt\"\n",
    "words_doc = df_corps.loc[song]['cleanText'].split()\n",
    "\n",
    "for word in words_doc:\n",
    "    count = frequency.get(word, 0)\n",
    "    frequency[word] = count + 1\n",
    "\n",
    "rank = 1\n",
    "column_header = ['Rank', 'Frequency', 'Frequency * Rank']\n",
    "df_rank = pd.DataFrame(columns = column_header)\n",
    "collection = sorted(frequency.items(), key = operator.itemgetter(1), reverse = True)\n",
    "\n",
    "for word, freq in collection:\n",
    "    df_rank.loc[word] = [rank, freq, rank * freq]\n",
    "    rank = rank + 1\n",
    "df_rank.loc[df_rank[\"Frequency\"]>10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do the same with more songs, and now we will give words of a song having the same frequency the same rank value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank(\"min\", ...) will give all the words in a song with the same number of occurances the same rank\n",
    "df_term_freq[\"rank\"] = df_term_freq.groupby(\"song_id\")[\"n\"].rank(\"min\", ascending=False)\n",
    "df_term_freq.sort_values(\"rank\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the ranks of each song against the term frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_term_freq = df_term_freq.sort_values(\"rank\", ascending=False)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "for song_id in song_list:\n",
    "    df_term_freq_selected = df_term_freq[df_term_freq['song_id'] == song_id]\n",
    "    x = df_term_freq_selected['rank']\n",
    "    y = df_term_freq_selected['term_frequency']\n",
    "    line, = ax.plot(x,y)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit exponent of power law\n",
    "\n",
    "We can try to fit this straight line and estimate its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df_term_freq_selected = df_term_freq[df_term_freq['song_id'].isin(song_list)]\n",
    "df_term_freq_selected = df_term_freq_selected[df_term_freq_selected['rank'].between(1,100) ]\n",
    "\n",
    "# print(df_term_freq_selected)\n",
    "\n",
    "x_log = np.log10(df_term_freq_selected['rank'].values.reshape(-1, 1))\n",
    "# print(x_log)\n",
    "y_log = np.log10(df_term_freq_selected['term_frequency'].values.reshape(-1,1))\n",
    "\n",
    "\n",
    "y_pred_log = LinearRegression()\n",
    "y_pred_log.fit(x_log, y_log)\n",
    "# model = LinearRegression().fit(x, y)\n",
    "print(f\"intercept: {y_pred_log.intercept_}\")\n",
    "print(f\"slope: {y_pred_log.coef_}\")\n",
    "\n",
    "l_model= y_pred_log.predict(x_log)\n",
    "# print(l_model)\n",
    "\n",
    "# plt.scatter(X_test_1og, Y_test_log,  color='gray')\n",
    "plt.plot(10 ** x_log, 10 ** l_model, color='red', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic versions of Zipf’s law have:\n",
    "\n",
    "$frequency∝\\frac{1}{rank}$\n",
    "\n",
    "and we have gotten quite close to -1 here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we draw the fitted line with the actual data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_term_freq = df_term_freq.sort_values(\"rank\", ascending=False)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "for song_id in song_list:\n",
    "    df_term_freq_selected = df_term_freq[df_term_freq['song_id'] == song_id]\n",
    "    x = df_term_freq_selected['rank']\n",
    "    y = df_term_freq_selected['term_frequency']\n",
    "    line, = ax.plot(x,y)\n",
    "\n",
    "x_vals = np.array(ax.get_xlim())\n",
    "y_vals = y_pred_log.intercept_ + y_pred_log.coef_ * x_vals\n",
    "print(x_vals)\n",
    "print(y_vals[0])\n",
    "ax.plot(x_vals, y_vals[0], '--')\n",
    "plt.plot(10 ** x_log, 10 ** l_model, color='red', linewidth=2)\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "rise": {
   "autolaunch": false,
   "backimage": "../../png/python-achtergrond.png",
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simpel"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
